<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-10-31T20:07:53+05:30</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sawan’s Blog</title><subtitle>Hello! I am Sawan Singh Mahara. Welcome to my website!</subtitle><author><name>Sawan Singh Mahara</name><email>ssmahara96@gmail.com</email></author><entry><title type="html">Memorylessness of the Geometric Random Variable</title><link href="http://localhost:4000/blog/Geometric-Random-Variable/" rel="alternate" type="text/html" title="Memorylessness of the Geometric Random Variable" /><published>2020-10-31T00:00:00+05:30</published><updated>2020-10-31T00:00:00+05:30</updated><id>http://localhost:4000/blog/Geometric-Random-Variable</id><content type="html" xml:base="http://localhost:4000/blog/Geometric-Random-Variable/">&lt;p&gt;Consider the case of winning a lottery. Either you win it or you don’t. Let the probability of winning the lottery be \(p\) and the probability of losing it be \((1-p)\)&lt;/p&gt;

&lt;p&gt;My strategy is that I keep buying tickets until I win. Then I stop.&lt;/p&gt;

&lt;p&gt;If I ask the question &lt;strong&gt;what is the probability that the  \(n^{th}\) ticket I buy makes me win?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The answer to it is actually uncertain, and so we model it using the help of a random variable called the &lt;strong&gt;geometric random variable&lt;/strong&gt;, denoted by \(X\)&lt;/p&gt;

&lt;h2 id=&quot;understanding-the-pmf&quot;&gt;Understanding the PMF&lt;/h2&gt;

&lt;p&gt;Let us  take an example, &lt;strong&gt;what is the probability that the  \(3^{rd}\) ticket I buy makes me win?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This means we have to fail on the first, with a probability \((1-p)\)&lt;/p&gt;

&lt;p&gt;AND&lt;/p&gt;

&lt;p&gt;Fail on the second, with a probability of \((1-p)\)&lt;/p&gt;

&lt;p&gt;AND&lt;/p&gt;

&lt;p&gt;Finally win on the third with a probability \(p\)&lt;/p&gt;

&lt;p&gt;So the question \(\mathbb{P}(X=3)\) is nothing but&lt;/p&gt;

\[\quad \quad \quad \quad \: \;\mathbb{P}(X=3)=(1-p)\cdot(1-p)\cdot p\]

\[\;\:\mathbb{P}(X=3)=(1-p)^{2}p\]

\[\;\;\;\;\;\mathbb{P}(X=3)=(1-p)^{3-1}p\]

&lt;p&gt;So the answer to &lt;strong&gt;what is the probability that the  \(n^{th}\) ticket I buy makes me win?&lt;/strong&gt; is&lt;/p&gt;

\[\mathbb{P}(X=n)=(1-p)^{n-1}\cdot p\]

&lt;p&gt;This is the &lt;strong&gt;PMF of the Geometric Random Variable&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;cdf&quot;&gt;CDF&lt;/h2&gt;

&lt;p&gt;The CDF of this random variable will be&lt;/p&gt;

\[\mathbb{P}(X\leq n)=\overset{n}{\underset{i=1}{\sum}}(1-p)^{i-1}\cdot p\]

&lt;p&gt;which can be simplified to be&lt;/p&gt;

\[\mathbb{P}(X\leq n)=1-(1-p)^{n-1}\]

&lt;p&gt;Which means that&lt;/p&gt;

\[\mathbb{P}(X\geq n)=(1-p)^{n-1}\]

&lt;h2 id=&quot;memorylessness&quot;&gt;Memorylessness&lt;/h2&gt;

&lt;p&gt;Memorylessness in the case of a geometric random variable would imply that the probability of winning after say, my \(10^{th}\) try would be the same as winning after my \(15^{th}\) try, given that I have already used up 5 tries.&lt;/p&gt;

&lt;p&gt;Or in other words, telling me that I have used up and not won in my last \(t\) tries, is as useful as not telling me anything at all.&lt;/p&gt;

&lt;p&gt;The probability that I win in the next, say \(s\) tries, is the same as that of me winning in the next \(s+t\) tries, after you tell me I have not won anything in my first \(t\) tries. Mathematically speaking, we mean&lt;/p&gt;

\[\mathbb P(X \geq s+t \mid X \geq t)=\mathbb P(X \geq s)\]

&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;/h2&gt;

&lt;p&gt;How do we justify this?&lt;/p&gt;

&lt;p&gt;Let’s use Baye’s theorem to help us out. Using it, we find that&lt;/p&gt;

\[\mathbb P(X \geq s+t \mid X \geq t)=\frac{\mathbb P(X \geq s+t , X \geq t)}{\mathbb P(X\geq t)}\]

&lt;p&gt;But what is \(\mathbb P(X \geq s+t , X \geq t)\)?&lt;/p&gt;

&lt;p&gt;It is the same as asking &lt;strong&gt;what is the probability that I win after \(s+t\) trials and also after \(t\) trials?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The first question of the probability of winning after \(s+t\) trials implies that&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We &lt;em&gt;consider winning after \(s+t\)&lt;/em&gt; trials&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and  the second question of winning after \(t\) trials considers two cases&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Winning after \(s+t\) trials&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Winning between the trials \(t\) and \(s+t\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So the only common event in these two questions (when they are jointly asked) is winning after \(s+t\) trials&lt;/p&gt;

&lt;p&gt;To generalise, we mean&lt;/p&gt;

\[\mathbb P(X \geq s+t , X \geq t)=\mathbb P(X \geq s+t)\]

&lt;p&gt;So, \(\mathbb P(X \geq s+t \mid X \geq t)\)  can be simplified as&lt;/p&gt;

&lt;p&gt;\(\mathbb P(X \geq s+t \mid X \geq t)=\frac{\mathbb P(X \geq s+t , X \geq t)}{\mathbb P(X\geq t)}\)
\(\quad \quad \quad \quad \quad \quad \quad \quad \quad\)&lt;/p&gt;

\[=\frac{\mathbb P(X \geq s+t)}{\mathbb P(X\geq t)}\]

\[\quad \quad \quad \quad \quad \quad \quad \quad \quad\]

\[=\frac{\mathbb P(X \geq s+t)}{\mathbb P(X\geq t)}\]

&lt;p&gt;But from earlier while deriving the CDF, we know that \(\mathbb{P}(X\geq n)=(1-p)^{n-1}\) so substituting this, we get&lt;/p&gt;

\[\mathbb P(X \geq s+t \mid X \geq t)=\frac{(1-p)^{s+t}}{(1-p)^{t}}\]

\[\quad \quad \quad \quad \quad \quad \quad \quad \quad \;\]

\[=(1-p)^{s}\]

&lt;p&gt;Which is nothing but \(\mathbb P(X \geq s)\), so this implies&lt;/p&gt;

\[\mathbb P(X \geq s+t \mid X \geq t)=\mathbb P(X \geq s)\]

&lt;p&gt;Which shows that the geometric random variable is in fact memoryless.
&lt;script type=&quot;text/javascript&quot; async=&quot;&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML&quot;&gt;
&lt;/script&gt;&lt;/p&gt;</content><author><name>Sawan Singh Mahara</name><email>ssmahara96@gmail.com</email></author><category term="Blog" /><category term="Probability" /><category term="Problems" /><summary type="html">Consider the case of winning a lottery. Either you win it or you don’t. Let the probability of winning the lottery be \(p\) and the probability of losing it be \((1-p)\) My strategy is that I keep buying tickets until I win. Then I stop. If I ask the question what is the probability that the \(n^{th}\) ticket I buy makes me win? The answer to it is actually uncertain, and so we model it using the help of a random variable called the geometric random variable, denoted by \(X\) Understanding the PMF Let us take an example, what is the probability that the \(3^{rd}\) ticket I buy makes me win? This means we have to fail on the first, with a probability \((1-p)\) AND Fail on the second, with a probability of \((1-p)\) AND Finally win on the third with a probability \(p\) So the question \(\mathbb{P}(X=3)\) is nothing but \[\quad \quad \quad \quad \: \;\mathbb{P}(X=3)=(1-p)\cdot(1-p)\cdot p\] \[\;\:\mathbb{P}(X=3)=(1-p)^{2}p\] \[\;\;\;\;\;\mathbb{P}(X=3)=(1-p)^{3-1}p\] So the answer to what is the probability that the \(n^{th}\) ticket I buy makes me win? is \[\mathbb{P}(X=n)=(1-p)^{n-1}\cdot p\] This is the PMF of the Geometric Random Variable CDF The CDF of this random variable will be \[\mathbb{P}(X\leq n)=\overset{n}{\underset{i=1}{\sum}}(1-p)^{i-1}\cdot p\] which can be simplified to be \[\mathbb{P}(X\leq n)=1-(1-p)^{n-1}\] Which means that \[\mathbb{P}(X\geq n)=(1-p)^{n-1}\] Memorylessness Memorylessness in the case of a geometric random variable would imply that the probability of winning after say, my \(10^{th}\) try would be the same as winning after my \(15^{th}\) try, given that I have already used up 5 tries. Or in other words, telling me that I have used up and not won in my last \(t\) tries, is as useful as not telling me anything at all. The probability that I win in the next, say \(s\) tries, is the same as that of me winning in the next \(s+t\) tries, after you tell me I have not won anything in my first \(t\) tries. Mathematically speaking, we mean \[\mathbb P(X \geq s+t \mid X \geq t)=\mathbb P(X \geq s)\] Proof How do we justify this? Let’s use Baye’s theorem to help us out. Using it, we find that \[\mathbb P(X \geq s+t \mid X \geq t)=\frac{\mathbb P(X \geq s+t , X \geq t)}{\mathbb P(X\geq t)}\] But what is \(\mathbb P(X \geq s+t , X \geq t)\)? It is the same as asking what is the probability that I win after \(s+t\) trials and also after \(t\) trials? The first question of the probability of winning after \(s+t\) trials implies that We consider winning after \(s+t\) trials and the second question of winning after \(t\) trials considers two cases Winning after \(s+t\) trials Winning between the trials \(t\) and \(s+t\) So the only common event in these two questions (when they are jointly asked) is winning after \(s+t\) trials To generalise, we mean \[\mathbb P(X \geq s+t , X \geq t)=\mathbb P(X \geq s+t)\] So, \(\mathbb P(X \geq s+t \mid X \geq t)\) can be simplified as \(\mathbb P(X \geq s+t \mid X \geq t)=\frac{\mathbb P(X \geq s+t , X \geq t)}{\mathbb P(X\geq t)}\) \(\quad \quad \quad \quad \quad \quad \quad \quad \quad\) \[=\frac{\mathbb P(X \geq s+t)}{\mathbb P(X\geq t)}\] \[\quad \quad \quad \quad \quad \quad \quad \quad \quad\] \[=\frac{\mathbb P(X \geq s+t)}{\mathbb P(X\geq t)}\] But from earlier while deriving the CDF, we know that \(\mathbb{P}(X\geq n)=(1-p)^{n-1}\) so substituting this, we get \[\mathbb P(X \geq s+t \mid X \geq t)=\frac{(1-p)^{s+t}}{(1-p)^{t}}\] \[\quad \quad \quad \quad \quad \quad \quad \quad \quad \;\] \[=(1-p)^{s}\] Which is nothing but \(\mathbb P(X \geq s)\), so this implies \[\mathbb P(X \geq s+t \mid X \geq t)=\mathbb P(X \geq s)\] Which shows that the geometric random variable is in fact memoryless.</summary></entry></feed>